, tuneGrid = expand.grid(k = c(1:300)), allowParallel=TRUE)
library(parallel)
library(doMC)
registerDoMC(7)
registerDoMC(8)
knnFit <- train(yc ~ ., data = train, method = "knn", trControl = ctrl, preProcess = c("center","scale")
, tuneGrid = expand.grid(k = c(1:300)), allowParallel=TRUE)
knnFit
library(MASS)
train = synth.te
test = synth.tr
library(class)
prc_test_pred <- knn(train = train[,-3], test = test[,-3], cl = train$yc, k=10)
y_value = test$yc
accracy = 1 - mean(prc_test_pred!=y_value)
accracy
plot(train[,c(1:2)])
points(train[train$yc == 1,c(1:2)],col = 'red')
library(caret)
train$yc = as.factor(train$yc)
trainX <- train[,-3]
preProcValues <- preProcess(x = trainX, method = c("center", "scale"))
preProcValues
set.seed(400)
ctrl <- trainControl(method="repeatedcv",repeats = 5) #,classProbs=TRUE,summaryFunction = twoClassSummary)
library(doParallel)
library(parallel)
library(doMC)
registerDoMC(8)
knnFit <- train(yc ~ ., data = train, method = "knn", trControl = ctrl, preProcess = c("center","scale")
, tuneGrid = expand.grid(k = c(1:300)), allowParallel=TRUE)
knnFit
ctrl <- trainControl(method="repeatedcv",repeats = 3) #,classProbs=TRUE,summaryFunction = twoClassSummary)
library(doParallel)
library(parallel)
library(doMC)
registerDoMC(8)
knnFit <- train(yc ~ ., data = train, method = "knn", trControl = ctrl, preProcess = c("center","scale")
, tuneGrid = expand.grid(k = c(1:300)), allowParallel=TRUE)
ctrl <- trainControl(method="repeatedcv",repeats = 3) #,classProbs=TRUE,summaryFunction = twoClassSummary)
library(doParallel)
library(parallel)
library(doMC)
registerDoMC(8)
knnFit <- train(yc ~ ., data = train, method = "knn", trControl = ctrl, preProcess = c("center","scale")
, tuneGrid = expand.grid(k = c(1:300)))
preProcValues
knnFit
plot(knnFit)
knnFit$results[knnFit$results$k == as.numeric(knnFit$bestTune),]$Accuracy
knnPredict <- predict(knnFit,newdata = test,type="prob" )
grid <- expand.grid(xs=seq(-1.1,1.1,0.01), ys=seq(-0.2,1.2,0.01))
prob.grid <-  predict(knnFit, newdata = grid,type="prob")
z=matrix(prob.grid[,1], nrow=length(seq(-1.1,1.1,0.01)))
contour(x=seq(-1.1,1.1,0.01), y=seq(-0.2,1.2,0.01), z = z, levels=0.5,
col="blue", drawlabels=FALSE, lwd=4,add = TRUE)
ctrl <- trainControl(method="repeatedcv",repeats = 3) #,classProbs=TRUE,summaryFunction = twoClassSummary)
library(parallel)
library(doMC)
registerDoMC(8)
knnFit <- train(yc ~ ., data = train, method = "knn", trControl = ctrl, preProcess = c("center","scale")
, tuneGrid = expand.grid(k = c(1:300)))
knnFit
plot(knnFit)
knnFit$results[knnFit$results$k == as.numeric(knnFit$bestTune),]$Accuracy
knnPredict <- predict(knnFit,newdata = test,type="prob" )
grid <- expand.grid(xs=seq(-1.1,1.1,0.01), ys=seq(-0.2,1.2,0.01))
prob.grid <-  predict(knnFit, newdata = grid,type="prob")
z=matrix(prob.grid[,1], nrow=length(seq(-1.1,1.1,0.01)))
contour(x=seq(-1.1,1.1,0.01), y=seq(-0.2,1.2,0.01), z = z, levels=0.5,
col="blue", drawlabels=FALSE, lwd=4,add = TRUE)
contour(x=seq(-1.1,1.1,0.01), y=seq(-0.2,1.2,0.01), z = z, levels=0.5,
col="blue", drawlabels=FALSE, lwd=4,add = TRUE)
contour(x=seq(-1.1,1.1,0.01), y=seq(-0.2,1.2,0.01), z = z, levels=0.5,
col="black", drawlabels=FALSE, lwd=4,add = TRUE)
ctrl <- trainControl(method="repeatedcv",repeats = 5) #,classProbs=TRUE,summaryFunction = twoClassSummary)
library(parallel)
library(doMC)
registerDoMC(8)
knnFit <- train(yc ~ ., data = train, method = "knn", trControl = ctrl, preProcess = c("center","scale")
, tuneGrid = expand.grid(k = c(1:300)))
knnFit
plot(knnFit)
knnFit$results[knnFit$results$k == as.numeric(knnFit$bestTune),]$Accuracy
knnPredict <- predict(knnFit,newdata = test,type="prob" )
grid <- expand.grid(xs=seq(-1.1,1.1,0.01), ys=seq(-0.2,1.2,0.01))
prob.grid <-  predict(knnFit, newdata = grid,type="prob")
z=matrix(prob.grid[,1], nrow=length(seq(-1.1,1.1,0.01)))
contour(x=seq(-1.1,1.1,0.01), y=seq(-0.2,1.2,0.01), z = z, levels=0.5,
col="black", drawlabels=FALSE, lwd=4,add = TRUE)
contour(x=seq(-1.1,1.1,0.01), y=seq(-0.2,1.2,0.01), z = z, levels=0.5,
col="red", drawlabels=FALSE, lwd=4,add = TRUE)
clusters <- kmeans(train[train$yc == 1,1:2], 2)
clusters
clusters$cluster
View(train)
train$yc =  clusters$cluster
View(train)
library(MASS)
train = synth.te
test = synth.tr
library(MASS)
train = synth.te
test = synth.tr
clusters <- kmeans(train[train$yc == 1,1:2], 2)
train[train$yc == 1,]
train[train$yc == 1,]$yc
train[train$yc == 1,]$yc
train[train$yc == 1,]$yc =  clusters$cluster
View(train)
train$yc = as.factor(train$yc)
trainX <- train[,-3]
preProcValues <- preProcess(x = trainX, method = c("center", "scale"))
preProcValues
set.seed(400)
ctrl <- trainControl(method="repeatedcv",repeats = 5) #,classProbs=TRUE,summaryFunction = twoClassSummary)
library(parallel)
library(doMC)
registerDoMC(8)
knnFit <- train(yc ~ ., data = train, method = "knn", trControl = ctrl, preProcess = c("center","scale")
, tuneGrid = expand.grid(k = c(1:300)))
knnFit
plot(knnFit)
knnFit$results[knnFit$results$k == as.numeric(knnFit$bestTune),]$Accuracy
knnPredict <- predict(knnFit,newdata = test,type="prob" )
View(test)
View(knnPredict)
grid <- expand.grid(xs=seq(-1.1,1.1,0.01), ys=seq(-0.2,1.2,0.01))
prob.grid <-  predict(knnFit, newdata = grid,type="prob")
z=matrix(prob.grid[,1], nrow=length(seq(-1.1,1.1,0.01)))
plot(train[,c(1:2)])
points(train[train$yc == 1,c(1:2)],col = 'red')
plot(train[,c(1:2)])
points(train[train$yc == 1,c(1:2)],col = 'red')
points(train[train$yc == 2,c(1:2)],col = 'blue')
contour(x=seq(-1.1,1.1,0.01), y=seq(-0.2,1.2,0.01), z = z, levels=0.5,
col="red", drawlabels=FALSE, lwd=4,add = TRUE)
knnPredicttrain <- predict(knnFit,newdata = train,type="prob" )
knnPredicttrain
knnPredicttrain <- predict(knnFit,newdata = train,type="prob" )[,1]
y_value = train$yc
predict_label_c1 <- predict(knnFit,newdata = train,type="prob" )[,1]>0
y_value = train$yc
acc = 1 - mean(predict_label_c1!=y_value)
accuracy[i] = acc
acc
predict_label_c1 <- predict(knnFit,newdata = train,type="prob" )[,1]>0.5
y_value = train$yc
acc = 1 - mean(predict_label_c1!=y_value)
acc
predict(knnFit,newdata = train,type="prob" )[,1]
predict(knnFit,newdata = train,type="prob" )[,1]>0.5
predict_label_c1 <- c(predict(knnFit,newdata = train,type="prob" )[,1]>0.5)
train$yc
c(train$yc == 0)
y_value = c(train$yc == 0)
acc = 1 - mean(predict_label_c1!=y_value)
acc
library(MASS)
train = synth.te
test = synth.tr
library(class)
plot(train[,c(1:2)])
points(train[train$yc == 1,c(1:2)],col = 'red')
library(caret)
train$yc = as.factor(train$yc)
trainX <- train[,-3]
preProcValues <- preProcess(x = trainX, method = c("center", "scale"))
preProcValues
set.seed(400)
ctrl <- trainControl(method="repeatedcv",repeats = 5) #,classProbs=TRUE,summaryFunction = twoClassSummary)
library(parallel)
library(doMC)
registerDoMC(8)
knnFit <- train(yc ~ ., data = train, method = "knn", trControl = ctrl, preProcess = c("center","scale")
, tuneGrid = expand.grid(k = c(1:300)))
plot(knnFit)
knnFit
knnFit$results[knnFit$results$k == as.numeric(knnFit$bestTune),]$Accuracy
knnPredict <- predict(knnFit,newdata = test,type="prob" )
grid <- expand.grid(xs=seq(-1.1,1.1,0.01), ys=seq(-0.2,1.2,0.01))
prob.grid <-  predict(knnFit, newdata = grid,type="prob")
z=matrix(prob.grid[,1], nrow=length(seq(-1.1,1.1,0.01)))
contour(x=seq(-1.1,1.1,0.01), y=seq(-0.2,1.2,0.01), z = z, levels=0.5,
col="red", drawlabels=FALSE, lwd=4,add = TRUE)
y_value = c(train$yc == 0)
knnPredict
acc = 1 - mean(c(knnPredict[,1]>0.5)!=y_value)
acc
c(knnPredict[,1]>0.5)
y_value
c(knnPredict[,1]>0.5)
y_value = c(test$yc == 0)
acc = 1 - mean(c(knnPredict[,1]>0.5)!=y_value)
acc
knnFit
prc_test_pred <- knn(train = train[,-3], test = test[,-3], cl = train$yc, k=64)
y_value = test$yc
accracy = 1 - mean(prc_test_pred!=y_value)
accracy
acc
clusters <- kmeans(train[train$yc == 1,1:2], 2)
train[train$yc == 1,]$yc =  clusters$cluster
train$yc = as.factor(train$yc)
trainX <- train[,-3]
preProcValues <- preProcess(x = trainX, method = c("center", "scale"))
preProcValues
set.seed(400)
ctrl <- trainControl(method="repeatedcv",repeats = 5,number = 10) #,classProbs=TRUE,summaryFunction = twoClassSummary)
library(parallel)
library(doMC)
registerDoMC(8)
knnFit <- train(yc ~ ., data = train, method = "knn", trControl = ctrl, preProcess = c("center","scale")
, tuneGrid = expand.grid(k = c(1:300)))
library(MASS)
train = synth.te
test = synth.tr
clusters <- kmeans(train[train$yc == 1,1:2], 2)
train[train$yc == 1,]$yc =  clusters$cluster
View(train)
train$yc = as.factor(train$yc)
trainX <- train[,-3]
preProcValues <- preProcess(x = trainX, method = c("center", "scale"))
preProcValues
set.seed(400)
ctrl <- trainControl(method="repeatedcv",repeats = 5,number = 10) #,classProbs=TRUE,summaryFunction = twoClassSummary)
library(parallel)
library(doMC)
registerDoMC(8)
knnFit <- train(yc ~ ., data = train, method = "knn", trControl = ctrl, preProcess = c("center","scale")
, tuneGrid = expand.grid(k = c(1:300)))
knnFit
plot(knnFit)
knnFit$results[knnFit$results$k == as.numeric(knnFit$bestTune),]$Accuracy
knnPredict <- predict(knnFit,newdata = test,type="prob" )
grid <- expand.grid(xs=seq(-1.1,1.1,0.01), ys=seq(-0.2,1.2,0.01))
prob.grid <-  predict(knnFit, newdata = grid,type="prob")
z=matrix(prob.grid[,1], nrow=length(seq(-1.1,1.1,0.01)))
plot(train[,c(1:2)])
points(train[train$yc == 1,c(1:2)],col = 'red')
points(train[train$yc == 2,c(1:2)],col = 'blue')
contour(x=seq(-1.1,1.1,0.01), y=seq(-0.2,1.2,0.01), z = z, levels=0.5,
col="red", drawlabels=FALSE, lwd=4,add = TRUE)
predict_label_c1 <- c(predict(knnFit,newdata = train,type="prob" )[,1]>0.5)
y_value = c(train$yc == 0)
acc = 1 - mean(predict_label_c1!=y_value)
acc
library(MASS)
train = synth.te
test = synth.tr
library(class)
prc_test_pred <- knn(train = train[,-3], test = test[,-3], cl = train$yc, k=64)
y_value = test$yc
accracy = 1 - mean(prc_test_pred!=y_value)
accracy
plot(train[,c(1:2)])
points(train[train$yc == 1,c(1:2)],col = 'red')
library(caret)
train$yc = as.factor(train$yc)
trainX <- train[,-3]
preProcValues <- preProcess(x = trainX, method = c("center", "scale"))
preProcValues
set.seed(400)
ctrl <- trainControl(method="repeatedcv",repeats = 5,number = 10) #,classProbs=TRUE,summaryFunction = twoClassSummary)
library(parallel)
library(doMC)
registerDoMC(8)
knnFit <- train(yc ~ ., data = train, method = "knn", trControl = ctrl, preProcess = c("center","scale")
, tuneGrid = expand.grid(k = c(1:300)))
knnFit
plot(knnFit)
knnFit$results[knnFit$results$k == as.numeric(knnFit$bestTune),]$Accuracy
grid <- expand.grid(xs=seq(-1.1,1.1,0.01), ys=seq(-0.2,1.2,0.01))
prob.grid <-  predict(knnFit, newdata = grid,type="prob")
z=matrix(prob.grid[,1], nrow=length(seq(-1.1,1.1,0.01)))
contour(x=seq(-1.1,1.1,0.01), y=seq(-0.2,1.2,0.01), z = z, levels=0.5,
col="red", drawlabels=FALSE, lwd=4,add = TRUE)
contour(x=seq(-1.1,1.1,0.01), y=seq(-0.2,1.2,0.01), z = z, levels=0.5,
col="red", drawlabels=FALSE, lwd=4,add = TRUE)
knnPredict <- predict(knnFit,newdata = test,type="prob" )
y_value = c(test$yc == 0)
acc = 1 - mean(c(knnPredict[,1]>0.5)!=y_value)
acc
knnFit$results[knnFit$results$k == as.numeric(knnFit$bestTune),]$Accuracy
predict_label_c1 <- c(predict(knnFit,newdata = train,type="prob" )[,1]>0.5)
y_value = c(train$yc == 0)
acc = 1 - mean(predict_label_c1!=y_value)
acc
clusters <- kmeans(train[train$yc == 1,1:2], 2)
train[train$yc == 1,]$yc =  clusters$cluster
train$yc = as.factor(train$yc)
trainX <- train[,-3]
preProcValues <- preProcess(x = trainX, method = c("center", "scale"))
preProcValues
set.seed(400)
ctrl <- trainControl(method="repeatedcv",repeats = 5,number = 10) #,classProbs=TRUE,summaryFunction = twoClassSummary)
library(parallel)
library(doMC)
registerDoMC(8)
knnFit <- train(yc ~ ., data = train, method = "knn", trControl = ctrl, preProcess = c("center","scale")
, tuneGrid = expand.grid(k = c(1:300)))
train
View(train)
train = synth.te
train$yc = as.factor(train$yc)
clusters <- kmeans(train[train$yc == 1,1:2], 2)
clusters
library(MASS)
train = synth.te
test = synth.tr
clusters <- kmeans(train[train$yc == 1,1:2], 2)
train[train$yc == 1,]$yc =  clusters$cluster
View(train)
train$yc = as.factor(train$yc)
trainX <- train[,-3]
preProcValues <- preProcess(x = trainX, method = c("center", "scale"))
preProcValues
set.seed(400)
ctrl <- trainControl(method="repeatedcv",repeats = 5,number = 10) #,classProbs=TRUE,summaryFunction = twoClassSummary)
library(parallel)
library(doMC)
registerDoMC(8)
knnFit <- train(yc ~ ., data = train, method = "knn", trControl = ctrl, preProcess = c("center","scale")
, tuneGrid = expand.grid(k = c(1:300)))
knnFit
plot(knnFit)
knnFit$results[knnFit$results$k == as.numeric(knnFit$bestTune),]$Accuracy
knnPredict <- predict(knnFit,newdata = test,type="prob" )
grid <- expand.grid(xs=seq(-1.1,1.1,0.01), ys=seq(-0.2,1.2,0.01))
prob.grid <-  predict(knnFit, newdata = grid,type="prob")
z=matrix(prob.grid[,1], nrow=length(seq(-1.1,1.1,0.01)))
plot(train[,c(1:2)])
points(train[train$yc == 1,c(1:2)],col = 'red')
points(train[train$yc == 2,c(1:2)],col = 'blue')
contour(x=seq(-1.1,1.1,0.01), y=seq(-0.2,1.2,0.01), z = z, levels=0.5,
col="red", drawlabels=FALSE, lwd=4,add = TRUE)
predict_label_c1 <- c(predict(knnFit,newdata = train,type="prob" )[,1]>0.5)
y_value = c(train$yc == 0)
acc = 1 - mean(predict_label_c1!=y_value)
acc
predict_label_c1 <- c(predict(knnFit,newdata = test,type="prob" )[,1]>0.5)
y_value = c(test$yc == 0)
acc = 1 - mean(predict_label_c1!=y_value)
acc
source('~/Desktop/relabel in lda/data/australiancredit/relabel.R', echo=TRUE)
setwd("~/Desktop/relabel in lda/data/australiancredit")
data <- read.table('australian.txt',header = F)
names(data)[15] = 'outcome'
table(data$outcome)
smp_size <- floor(0.75 * nrow(data))
set.seed(113)
train_ind <- sample(seq_len(nrow(data)), size = smp_size)
train <- data[train_ind, ]
test <- data[-train_ind, ]
library(MASS)
train.qda <- qda(as.formula(outcome~.), data = train)
result = predict(train.qda, newdata = train)$posterior
predict_label_c1 = result[,2]>result[,1]
y_value = train$outcome
accracy = 1 - mean(predict_label_c1!=y_value)
accracy
train.qda <- lda(as.formula(outcome~.), data = train)
result = predict(train.qda, newdata = train)$posterior
predict_label_c1 = result[,2]>result[,1]
y_value = train$outcome
accracy = 1 - mean(predict_label_c1!=y_value)
accracy
train.qda <- lda(as.formula(outcome~.), data = train)
result = predict(train.qda, newdata = train)$posterior
predict_label_c1 = result[,2]>result[,1]
y_value = train$outcome
accracy = 1 - mean(predict_label_c1!=y_value)
accracy
result = predict(train.qda, newdata = test)$posterior
predict_label_c1 = result[,2]>result[,1]
y_value = test$outcome
accracy = 1 - mean(predict_label_c1!=y_value)
accracy
smp_size <- floor(0.75 * nrow(data))
set.seed(120)
train_ind <- sample(seq_len(nrow(data)), size = smp_size)
train <- data[train_ind, ]
test <- data[-train_ind, ]
library(MASS)
train.qda <- lda(as.formula(outcome~.), data = train)
result = predict(train.qda, newdata = train)$posterior
predict_label_c1 = result[,2]>result[,1]
y_value = train$outcome
accracy = 1 - mean(predict_label_c1!=y_value)
accracy
result = predict(train.qda, newdata = test)$posterior
predict_label_c1 = result[,2]>result[,1]
y_value = test$outcome
accracy = 1 - mean(predict_label_c1!=y_value)
accracy
setwd("~/Desktop/relabel in lda/data/banknote")
data <- read.table('data_banknote_authentication.txt',header = F,sep = ',')
names(data)[5] = 'outcome'
table(data$outcome)
smp_size <- floor(0.75 * nrow(data))
set.seed(113)
train_ind <- sample(seq_len(nrow(data)), size = smp_size)
train <- data[train_ind, ]
test <- data[-train_ind, ]
table(data$outcome)
View(data)
library(MASS)
train.qda <- qda(as.formula(outcome~.), data = train)
result = predict(train.qda, newdata = train)$posterior
predict_label_c1 = result[,2]>result[,1]
y_value = train$outcome
accracy = 1 - mean(predict_label_c1!=y_value)
accracy
result = predict(train.qda, newdata = test)$posterior
predict_label_c1 = result[,2]>result[,1]
y_value = test$outcome
accracy = 1 - mean(predict_label_c1!=y_value)
accracy
train_generate = function(x){
default = train[which(train$outcome == 1),]
non_default = train[which(train$outcome == 0),]
new.data = as.data.frame(rbind(non_default,default))
new.data = new.data[,c(-5)]
c = rep("c2",nrow(default))
c[which(x == 1)] = "c3"
new.data$class = c(rep("c1",nrow(non_default)), c)
return(new.data)
}
evalFunc <- function(chromosome){
if(sum(chromosome) == 0 | sum(chromosome) == length(chromosome)){
return(0)
} else {
mldata = train_generate(chromosome)
#f <- as.formula(paste("class ~ 1|", paste(names(mldata)[c(1,2)], collapse = " + ")))
train.lda <- qda(as.formula(class~.), data = mldata)
#mlogit.model<-mlogit(class ~ 1 | x1 + x2 , data = mldata, reflevel="c1")
result = predict(train.lda, newdata = mldata)$posterior
results = result[,2]+result[,3]
predict_label_c1 = c(result[,1]>results)
y_value = c(mldata$class == 'c1')
er = Error.rate(Fit = predict_label_c1, Y=y_value)
accracy = 1-er
return(accracy)
}
}
chromosome = sample(c(0,1), size = sum(train$outcome),replace = TRUE)
x = chromosome
library(wSVM)
evalFunc(chromosome)
library(GA)
library(memoise)
mfitness <- memoise(evalFunc)
GA = ga("binary", fitness = mfitness, nBits = nrow(train[which(train$outcome == 1),]), popSize = 100, maxiter = 1000, seed = 1, monitor = FALSE, parallel = 8)
forget(mfitness)
summary(GA)
plot(GA)
sol = GA@solution[1,]
c1 = train[which(train$outcome == 1),][which(sol == 1),]
c2 = train[which(train$outcome == 1),][which(sol == 0),]
non_default = train[which(train$outcome == 0),]
relabel = rbind(non_default,c1,c2)
relabel$outcome = c(rep('c1',nrow(non_default)),rep('c2',nrow(c1)),rep('c3',nrow(c2)))
train.lda <- qda(as.formula(outcome~.), data = relabel)
result = predict(train.lda, newdata = test)$posterior
predict_label_c1 = (result[,2]+result[,3])>result[,1]
y_value = test$outcome
er = Error.rate(Fit = predict_label_c1, Y=y_value)
accracy = 1-er
accracy
setwd("~/Desktop/relabel in lda/data/Caesarian")
library(MASS)
data = read.csv(file="caesarian.csv",header=TRUE,sep=",")
View(data)
setwd("~/Desktop/relabel in lda/data/echocardiogram")
my_data <- read.delim('echocardiogramdata.txt',header = T, sep = ",")
View(my_data)
my_data = my_data[as.numeric(as.character(my_data$survival))>11,]
setwd("~/Desktop/relabel in lda/data/crimedata")
data <- read.table('pop_failures.txt',header = T)
View(data)
data = data[,-c(1,2)]
View(data)
data$outcome = !data$outcome
smp_size <- floor(0.75 * nrow(data))
set.seed(123)
train_ind <- sample(seq_len(nrow(data)), size = smp_size)
train <- data[train_ind, ]
test <- data[-train_ind, ]
library(MASS)
train.qda <- qda(as.formula(outcome~.), data = train)
result = predict(train.qda, newdata = train)$posterior
predict_label_c1 = result[,2]>result[,1]
y_value = train$outcome
accracy = 1 - mean(predict_label_c1!=y_value)
accracy
result = predict(train.qda, newdata = test)$posterior
predict_label_c1 = result[,2]>result[,1]
y_value = test$outcome
accracy = 1 - mean(predict_label_c1!=y_value)
accracy
train.qda <- lda(as.formula(outcome~.), data = train)
result = predict(train.qda, newdata = train)$posterior
predict_label_c1 = result[,2]>result[,1]
y_value = train$outcome
accracy = 1 - mean(predict_label_c1!=y_value)
accracy
result = predict(train.qda, newdata = test)$posterior
predict_label_c1 = result[,2]>result[,1]
y_value = test$outcome
accracy = 1 - mean(predict_label_c1!=y_value)
accracy
View(train)
