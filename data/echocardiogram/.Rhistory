y_value = c(mldata$class == 'c1')
er = Error.rate(Fit = predict_label_c1, Y=y_value)
accracy = 1-er
return(accracy)
}
}
clusters <- kmeans(train[train$yc == 1,1:2], 2)
sol = clusters$cluster
c1 = train[which(train$yc == 1),][which(sol == 1),]
c2 = train[which(train$yc == 1),][which(sol == 2),]
plot(train[,c(1:2)])
points(c1[c(1:2)],col = 'red')
points(c2[c(1:2)],col = 'blue')
#chromosome = sample(c(0,1), size = 500,replace = TRUE)
chromosome = c(sol-1)
suggestion = chromosome
pr = table(suggestion)/length(suggestion)
result <- t(sapply(1:99, function(x) {sample(c(0, 1), size = length(suggestion), replace = TRUE, prob = pr)}))
suggestion = rbind(suggestion, result)
evalFunc(suggestion[1,])
library(GA)
library(memoise)
mfitness <- memoise(evalFunc)
GA = ga("binary", fitness = mfitness, nBits = nrow(train[which(train$yc == 1),]), popSize = 100, maxiter = 1000, seed = 1, monitor = FALSE, parallel = 8, suggestions = suggestion)
forget(mfitness)
summary(GA)
plot(GA)
sol = GA@solution[1,]
c1 = train[which(train$yc == 1),][which(sol == 1),]
c2 = train[which(train$yc == 1),][which(sol == 0),]
plot(train[,c(1:2)])
points(c1[c(1:2)],col = 'red')
points(c2[c(1:2)],col = 'blue')
clusters <- kmeans(train[train$yc == 1,1:2], 2)
sol = clusters$cluster
c1 = train[which(train$yc == 1),][which(sol == 1),]
c2 = train[which(train$yc == 1),][which(sol == 2),]
plot(train[,c(1:2)])
points(c1[c(1:2)],col = 'red')
points(c2[c(1:2)],col = 'blue')
non_default = train[which(train$yc == 0),]
relabel = rbind(non_default,c1,c2)
relabel$yc = c(rep('c1',nrow(non_default)),rep('c2',nrow(c1)),rep('c3',nrow(c2)))
train.lda <- lda(as.formula(yc~xs+ys), data = relabel)
result = predict(train.lda, newdata = test)$posterior
predict_label_c1 = (result[,2]+result[,3])>result[,1]
y_value = test$yc
er = Error.rate(Fit = predict_label_c1, Y=y_value)
accracy = 1-er
accracy
grid <- expand.grid(xs=seq(-1.1,1.1,0.01), ys=seq(-0.2,1.2,0.01))
prob.grid <-  predict(train.qda, newdata = grid)$posterior[,1]
prob.grid <-  predict(train.lda, newdata = grid)$posterior[,1]
z=matrix(prob.grid, nrow=length(seq(-1.1,1.1,0.01)))
# plot the boundary
contour(x=seq(-1.1,1.1,0.01), y=seq(-0.2,1.2,0.01), z = z, levels=0.5,
col="blue", drawlabels=FALSE, lwd=4)
# add points from test dataset
points(train[,c(1:2)])
points(c1[c(1:2)],col = 'red')
points(c2[c(1:2)],col = 'blue')
train.qda <- lda(as.formula(yc~xs+ys), data = train)
prob.grid <-  predict(train.qda, newdata = grid)$posterior[,1]
z=matrix(prob.grid, nrow=length(seq(-1.1,1.1,0.01)))
# plot the boundary
contour(x=seq(-1.1,1.1,0.01), y=seq(-0.2,1.2,0.01), z = z, levels=0.5,
col="black", drawlabels=FALSE, lwd=4,add = TRUE)
clusters <- kmeans(train[train$yc == 1,1:2], 3)
sol = clusters$cluster
c1 = train[which(train$yc == 1),][which(sol == 1),]
c2 = train[which(train$yc == 1),][which(sol == 2),]
c3 = train[which(train$yc == 1),][which(sol == 3),]
c1 = train[which(train$yc == 1),][which(class == 0),]
clusters <- kmeans(train[train$yc == 1,1:2], 3)
sol = clusters$cluster
c1 = train[which(train$yc == 1),][which(sol == 1),]
c2 = train[which(train$yc == 1),][which(sol == 2),]
c3 = train[which(train$yc == 1),][which(sol == 3),]
non_default = train[which(train$yc == 0),]
relabel = rbind(non_default,c1,c2,c3)
relabel$yc = c(rep('c1',nrow(non_default)),rep('c2',nrow(c1)),rep('c3',nrow(c2)),rep('c4',nrow(c3)))
train.qda <- lda(as.formula(yc~xs+ys), data = relabel)
result = predict(train.qda, newdata = test)$posterior
predict_label_c1 = (1-result[,1])>result[,1]
y_value = test$yc
er = Error.rate(Fit = predict_label_c1, Y=y_value)
accracy = 1-er
accracy
grid <- expand.grid(xs=seq(-1.1,1.1,0.01), ys=seq(-0.2,1.2,0.01))
prob.grid <-  predict(train.qda, newdata = grid)$posterior[,1]
z=matrix(prob.grid, nrow=length(seq(-1.1,1.1,0.01)))
# plot the boundary
contour(x=seq(-1.1,1.1,0.01), y=seq(-0.2,1.2,0.01), z = z, levels=0.5,
col="blue", drawlabels=FALSE, lwd=4,add = TRUE)
library(MASS)
train = synth.te
test = synth.tr
plot(train[,c(1:2)])
points(train[train$yc == 1,c(1:2)],col = 'red')
train.qda <- lda(as.formula(yc~xs+ys), data = train)
result = predict(train.qda, newdata = train)$posterior
predict_label_c1 = result[,2]>result[,1]
y_value = train$yc
accracy = 1 - mean(predict_label_c1!=y_value)
accracy
#accracy,0.9
grid <- expand.grid(xs=seq(-1.1,1.1,0.01), ys=seq(-0.2,1.2,0.01))
prob.grid <-  predict(train.qda, newdata = grid)$posterior[,1]
z=matrix(prob.grid, nrow=length(seq(-1.1,1.1,0.01)))
# plot the boundary
contour(x=seq(-1.1,1.1,0.01), y=seq(-0.2,1.2,0.01), z = z, levels=0.5,
col="black", drawlabels=FALSE, lwd=4,add = TRUE)
library(MASS)
train = synth.te
test = synth.tr
plot(train[,c(1:2)])
points(train[train$yc == 1,c(1:2)],col = 'red')
train.qda <- lda(as.formula(yc~xs+ys), data = train)
result = predict(train.qda, newdata = train)$posterior
predict_label_c1 = result[,2]>result[,1]
y_value = train$yc
accracy = 1 - mean(predict_label_c1!=y_value)
accracy
library(MASS)
train = synth.te
test = synth.tr
plot(train[,c(1:2)])
points(train[train$yc == 1,c(1:2)],col = 'red')
train.qda <- qda(as.formula(yc~xs+ys), data = train)
result = predict(train.qda, newdata = train)$posterior
predict_label_c1 = result[,2]>result[,1]
y_value = train$yc
accracy = 1 - mean(predict_label_c1!=y_value)
accracy
#accracy,0.9
grid <- expand.grid(xs=seq(-1.1,1.1,0.01), ys=seq(-0.2,1.2,0.01))
prob.grid <-  predict(train.qda, newdata = grid)$posterior[,1]
z=matrix(prob.grid, nrow=length(seq(-1.1,1.1,0.01)))
# plot the boundary
contour(x=seq(-1.1,1.1,0.01), y=seq(-0.2,1.2,0.01), z = z, levels=0.5,
col="black", drawlabels=FALSE, lwd=4,add = TRUE)
result = predict(train.qda, newdata = test)$posterior
predict_label_c1 = result[,2]>result[,1]
y_value = test$yc
accracy = 1 - mean(predict_label_c1!=y_value)
accracy
train_generate = function(x){
default = train[which(train$yc == 1),]
non_default = train[which(train$yc == 0),]
new.data = as.data.frame(rbind(non_default,default))
new.data = new.data[,c(1,2)]
colnames(new.data) = c("x1","x2")
c = rep("c2",nrow(default))
c[which(x == 1)] = "c3"
new.data$class = c(rep("c1",nrow(non_default)), c)
return(new.data)
}
evalFunc <- function(chromosome){
if(sum(chromosome) == 0 | sum(chromosome) == length(chromosome)){
return(0)
} else {
mldata = train_generate(chromosome)
#f <- as.formula(paste("class ~ 1|", paste(names(mldata)[c(1,2)], collapse = " + ")))
train.lda <- lda(as.formula(class~x1+x2), data = mldata)
#mlogit.model<-mlogit(class ~ 1 | x1 + x2 , data = mldata, reflevel="c1")
result = predict(train.lda, newdata = mldata)$posterior
results = result[,2]+result[,3]
predict_label_c1 = c(result[,1]>results)
y_value = c(mldata$class == 'c1')
er = Error.rate(Fit = predict_label_c1, Y=y_value)
accracy = 1-er
return(accracy)
}
}
evalFunc <- function(chromosome){
if(sum(chromosome) == 0 | sum(chromosome) == length(chromosome)){
return(0)
} else {
mldata = train_generate(chromosome)
#f <- as.formula(paste("class ~ 1|", paste(names(mldata)[c(1,2)], collapse = " + ")))
train.lda <- qda(as.formula(class~x1+x2), data = mldata)
#mlogit.model<-mlogit(class ~ 1 | x1 + x2 , data = mldata, reflevel="c1")
result = predict(train.lda, newdata = mldata)$posterior
results = result[,2]+result[,3]
predict_label_c1 = c(result[,1]>results)
y_value = c(mldata$class == 'c1')
er = Error.rate(Fit = predict_label_c1, Y=y_value)
accracy = 1-er
return(accracy)
}
}
clusters <- kmeans(train[train$yc == 1,1:2], 2)
sol = clusters$cluster
#chromosome = sample(c(0,1), size = 500,replace = TRUE)
chromosome = c(sol-1)
suggestion = chromosome
pr = table(suggestion)/length(suggestion)
result <- t(sapply(1:99, function(x) {sample(c(0, 1), size = length(suggestion), replace = TRUE, prob = pr)}))
suggestion = rbind(suggestion, result)
evalFunc(suggestion[1,])
library(GA)
library(memoise)
mfitness <- memoise(evalFunc)
GA = ga("binary", fitness = mfitness, nBits = nrow(train[which(train$yc == 1),]), popSize = 100, maxiter = 1000, seed = 1, monitor = FALSE, parallel = 8, suggestions = suggestion)
forget(mfitness)
summary(GA)
plot(GA)
sol = GA@solution[1,]
c1 = train[which(train$yc == 1),][which(sol == 1),]
c2 = train[which(train$yc == 1),][which(sol == 0),]
non_default = train[which(train$yc == 0),]
relabel = rbind(non_default,c1,c2)
relabel$yc = c(rep('c1',nrow(non_default)),rep('c2',nrow(c1)),rep('c3',nrow(c2)))
train.lda <- lda(as.formula(yc~xs+ys), data = relabel)
result = predict(train.lda, newdata = test)$posterior
predict_label_c1 = (result[,2]+result[,3])>result[,1]
y_value = test$yc
er = Error.rate(Fit = predict_label_c1, Y=y_value)
accracy = 1-er
accracy
grid <- expand.grid(xs=seq(-1.1,1.1,0.01), ys=seq(-0.2,1.2,0.01))
prob.grid <-  predict(train.lda, newdata = grid)$posterior[,1]
z=matrix(prob.grid, nrow=length(seq(-1.1,1.1,0.01)))
# plot the boundary
contour(x=seq(-1.1,1.1,0.01), y=seq(-0.2,1.2,0.01), z = z, levels=0.5,
col="blue", drawlabels=FALSE, lwd=4)
# plot the boundary
contour(x=seq(-1.1,1.1,0.01), y=seq(-0.2,1.2,0.01), z = z, levels=0.5,
col="blue", drawlabels=FALSE, lwd=4,add = T)
library(MASS)
train = synth.te
test = synth.tr
l = length(decimal2binary(2))
Integer2Gray = function(x){
sapply(x, function(x) {binary2gray(decimal2binary(x,l))})
}
Gray2Integer = function(x){
binary2decimal(gray2binary(x))
}
i = sample(c(0,1,2),size = 500,replace = TRUE)
library(GA)
chromosome = as.vector(Integer2Gray(i))
train_generate = function(x){
default = train[which(train$yc == 1),]
non_default = train[which(train$yc == 0),]
new.data = as.data.frame(rbind(non_default,default))
new.data = new.data[,c(1,2)]
colnames(new.data) = c("x1","x2")
c = rep("c2",nrow(default))
c[which(x == 1)] = "c3"
c[which(x == 2)] = "c4"
new.data$class = c(rep("c1",nrow(non_default)), c)
return(new.data)
}
evalFunc <- function(chromosome){
l = length(decimal2binary(2))
element = matrix(chromosome,l)
class = apply(element, 2, Gray2Integer)
if(length(unique(class)) < 3 || max(class) > 2){
return(0.5)
} else {
mldata = train_generate(class)
train.lda <- lda(as.formula(class~x1+x2), data = mldata)
#mlogit.model<-mlogit(class ~ 1 | x1 + x2 , data = mldata, reflevel="c1")
result = predict(train.lda, newdata = mldata)$posterior
results = 1 - result[,1]
predict_label_c1 = result[,1]>results
y_value = mldata$class == 'c1'
er = Error.rate(Fit = predict_label_c1, Y=y_value)
accracy = 1-er
return(accracy)
}
}
train.lda <- qda(as.formula(class~x1+x2), data = mldata)
evalFunc <- function(chromosome){
l = length(decimal2binary(2))
element = matrix(chromosome,l)
class = apply(element, 2, Gray2Integer)
if(length(unique(class)) < 3 || max(class) > 2){
return(0.5)
} else {
mldata = train_generate(class)
train.lda <- qda(as.formula(class~x1+x2), data = mldata)
#mlogit.model<-mlogit(class ~ 1 | x1 + x2 , data = mldata, reflevel="c1")
result = predict(train.lda, newdata = mldata)$posterior
results = 1 - result[,1]
predict_label_c1 = result[,1]>results
y_value = mldata$class == 'c1'
er = Error.rate(Fit = predict_label_c1, Y=y_value)
accracy = 1-er
return(accracy)
}
}
i = sample(c(0,1,2),size = 500,replace = TRUE)
library(GA)
chromosome = as.vector(Integer2Gray(i))
#chromosome
evalFunc(chromosome)
clusters <- kmeans(train[train$yc == 1,1:2], 3)
sol = clusters$cluster
library(GA)
library(memoise)
i=sol-1
suggestion = t(as.matrix(i))
pr = table(suggestion)/length(suggestion)
result <- t(sapply(1:99, function(x) {sample(c(0, 1, 2), size = length(suggestion), replace = TRUE, prob = pr)}))
suggestion = rbind(suggestion, result)
suggestion = t(apply(suggestion, 1, function(x) as.vector(Integer2Gray(x))))
evalFunc(suggestion[1,])
mfitness <- memoise(evalFunc)
GA = ga("binary", fitness = mfitness, nBits = l*nrow(train[which(train$yc == 1),]), popSize = 1000, maxiter = 100, seed = 1, monitor = FALSE, parallel = 7,suggestions = suggestion)
forget(mfitness)
summary(GA)
plot(GA)
sol = GA@solution[1,]
element = matrix(sol,l)
class = apply(element, 2, Gray2Integer)
clusters <- kmeans(train[train$yc == 1,1:2], 3)
c1 = train[which(train$yc == 1),][which(class == 0),]
c2 = train[which(train$yc == 1),][which(class == 1),]
c3 = train[which(train$yc == 1),][which(class == 2),]
plot(train[,c(1:2)])
points(c1[c(1:2)],col = 'red')
points(c2[c(1:2)],col = 'blue')
points(c3[c(1:2)],col = 'green')
non_default = train[which(train$yc == 0),]
relabel = rbind(non_default,c1,c2,c3)
relabel$yc = c(rep('c1',nrow(non_default)),rep('c2',nrow(c1)),rep('c3',nrow(c2)),rep('c4',nrow(c3)))
train.qda <- qda(as.formula(yc~xs+ys), data = relabel)
result = predict(train.qda, newdata = test)$posterior
predict_label_c1 = (1-result[,1])>result[,1]
y_value = test$yc
er = Error.rate(Fit = predict_label_c1, Y=y_value)
accracy = 1-er
accracy
prob.grid <-  predict(train.qda, newdata = grid)$posterior[,1]
z=matrix(prob.grid, nrow=length(seq(-1.1,1.1,0.01)))
# plot the boundary
contour(x=seq(-1.1,1.1,0.01), y=seq(-0.2,1.2,0.01), z = z, levels=0.5,
col="blue", drawlabels=FALSE, lwd=4,add = TRUE)
# add points from test dataset
points(train[,c(1:2)])
points(c1[c(1:2)],col = 'red')
points(c2[c(1:2)],col = 'blue')
contour(x=seq(-1.1,1.1,0.01), y=seq(-0.2,1.2,0.01), z = z, levels=0.5,
col="black", drawlabels=FALSE, lwd=4,add = TRUE)
setwd("~/Desktop/relabel in lda/data/echocardiogram")
my_data <- read.delim('echocardiogramdata.txt',header = T, sep = ",")
View(my_data)
setwd("~/Desktop/relabel in lda/data/echocardiogram")
my_data <- read.delim('echocardiogramdata.txt',header = T, sep = ",")
my_data = my_data[as.numeric(as.character(my_data$survival))>11,]
View(my_data)
#my_data = my_data[,c(3:7,9,13)]
#table(my_data$alive.at.1)
my_data = my_data[,c(2:7,9)]
my_data = my_data[complete.cases(my_data), ]
View(my_data)
View(my_data)
table(my_data$epss)
Reduce(union, lapply(x, function(a) which(rowSums(my_data == "?") > 0)))
Reduce(union, lapply(my_data, function(a) which(rowSums(a == "?") > 0)))
my_data$epss == "?"
sum(my_data$epss == "?")
which(my_data$epss == "?")
x = my_data$epss
which(x == "?")
apply(X = my_data, MARGIN = , FUN = function(x){which(x == "?")})
apply(X = my_data, MARGIN = 2, FUN = function(x){which(x == "?")})
sapply(X = my_data, MARGIN = 2, FUN = function(x){which(x == "?")})
sapply(X = my_data, FUN = function(x){which(x == "?")})
unlist(sapply(X = my_data, MARGIN = 2, FUN = function(x){which(x == "?")}))
unlist(apply(X = my_data, MARGIN = 2, FUN = function(x){which(x == "?")}))
unique(unlist(apply(X = my_data, MARGIN = 2, FUN = function(x){which(x == "?")})))
index = unique(unlist(apply(X = my_data, MARGIN = 2, FUN = function(x){which(x == "?")})))
my_data = my_data[-index,]
View(my_data)
as.numeric(as.character(my_data[,1]))
my_data[,1]
for(i in 1:7){
my_data[,i] = as.numeric(as.character(my_data[,i]))
}
View(my_data)
train.qda <- qda(as.formula(still.alive~.), data = my_data)
library(MASS)
train.qda <- lda(as.formula(still.alive~.), data = my_data)
result = predict(train.qda, newdata = data)$posterior
result = predict(train.qda, newdata = my_data)$posterior
predict_label_c1 = result[,2]>result[,1]
y_value = data$still.alive
y_value = my_data$still.alive
accracy = 1 - mean(predict_label_c1!=y_value)
accracy
train = my_data
chromosome = sample(c(0,1), size = sum(train$still.alive),replace = TRUE)
x = chromosome
#train = data
library(wSVM)
evalFunc(chromosome)
train_generate = function(x){
default = train[which(train$still.alive == 1),]
non_default = train[which(train$still.alive == 0),]
new.data = as.data.frame(rbind(non_default,default))
new.data = new.data[,c(-15)]
c = rep("c2",nrow(default))
c[which(x == 1)] = "c3"
new.data$class = c(rep("c1",nrow(non_default)), c)
return(new.data)
}
evalFunc <- function(chromosome){
if(sum(chromosome) == 0 | sum(chromosome) == length(chromosome)){
return(0)
} else {
mldata = train_generate(chromosome)
#f <- as.formula(paste("class ~ 1|", paste(names(mldata)[c(1,2)], collapse = " + ")))
train.lda <- lda(as.formula(class~.), data = mldata)
#mlogit.model<-mlogit(class ~ 1 | x1 + x2 , data = mldata, reflevel="c1")
result = predict(train.lda, newdata = mldata)$posterior
results = result[,2]+result[,3]
predict_label_c1 = c(result[,1]>results)
y_value = c(mldata$class == 'c1')
er = Error.rate(Fit = predict_label_c1, Y=y_value)
accracy = 1-er
return(accracy)
}
}
evalFunc(chromosome)
View(my_data)
train_generate = function(x){
default = train[which(train$still.alive == 1),]
non_default = train[which(train$still.alive == 0),]
new.data = as.data.frame(rbind(non_default,default))
new.data = new.data[,c(-1)]
c = rep("c2",nrow(default))
c[which(x == 1)] = "c3"
new.data$class = c(rep("c1",nrow(non_default)), c)
return(new.data)
}
evalFunc <- function(chromosome){
if(sum(chromosome) == 0 | sum(chromosome) == length(chromosome)){
return(0)
} else {
mldata = train_generate(chromosome)
#f <- as.formula(paste("class ~ 1|", paste(names(mldata)[c(1,2)], collapse = " + ")))
train.lda <- lda(as.formula(class~.), data = mldata)
#mlogit.model<-mlogit(class ~ 1 | x1 + x2 , data = mldata, reflevel="c1")
result = predict(train.lda, newdata = mldata)$posterior
results = result[,2]+result[,3]
predict_label_c1 = c(result[,1]>results)
y_value = c(mldata$class == 'c1')
er = Error.rate(Fit = predict_label_c1, Y=y_value)
accracy = 1-er
return(accracy)
}
}
train = my_data
chromosome = sample(c(0,1), size = sum(train$still.alive),replace = TRUE)
x = chromosome
#train = data
library(wSVM)
evalFunc(chromosome)
mfitness <- memoise(evalFunc)
library(GA)
library(memoise)
mfitness <- memoise(evalFunc)
GA = ga("binary", fitness = mfitness, nBits = nrow(train[which(train$outcome == 1),]), popSize = 100, maxiter = 1000, seed = 1, monitor = FALSE, parallel = 8)
GA = ga("binary", fitness = mfitness, nBits = nrow(train[which(train$outcome == 1),]), popSize = 10, maxiter = 100, seed = 1, monitor = FALSE, parallel = 8)
GA = ga("binary", fitness = mfitness, nBits = nrow(train[which(train$still.alive == 1),]), popSize = 10, maxiter = 100, seed = 1, monitor = FALSE, parallel = 8)
forget(mfitness)
summary(GA)
plot(GA)
sol = GA@solution[1,]
c1 = train[which(train$still.alive == 1),][which(sol == 1),]
c2 = train[which(train$still.alive == 1),][which(sol == 0),]
non_default = train[which(train$outcome == 0),]
relabel = rbind(non_default,c1,c2)
relabel$outcome = c(rep('c1',nrow(non_default)),rep('c2',nrow(c1)),rep('c3',nrow(c2)))
train.lda <- lda(as.formula(outcome~.), data = relabel)
train.lda <- lda(as.formula(still.alive~.), data = relabel)
View(relabel)
sol = GA@solution[1,]
c1 = train[which(train$still.alive == 1),][which(sol == 1),]
c2 = train[which(train$still.alive == 1),][which(sol == 0),]
non_default = train[which(train$still.alive == 0),]
relabel = rbind(non_default,c1,c2)
relabel$outcome = c(rep('c1',nrow(non_default)),rep('c2',nrow(c1)),rep('c3',nrow(c2)))
train.lda <- lda(as.formula(still.alive~.), data = relabel)
result = predict(train.lda, newdata = test)$posterior
result = predict(train.lda, newdata = train)$posterior
View(train)
train.lda <- lda(as.formula(still.alive~.), data = relabel)
train.lda
relabel
View(relabel)
sol = GA@solution[1,]
c1 = train[which(train$still.alive == 1),][which(sol == 1),]
c2 = train[which(train$still.alive == 1),][which(sol == 0),]
non_default = train[which(train$still.alive == 0),]
relabel = rbind(non_default,c1,c2)
relabel$still.alive = c(rep('c1',nrow(non_default)),rep('c2',nrow(c1)),rep('c3',nrow(c2)))
train.lda <- lda(as.formula(still.alive~.), data = relabel)
result = predict(train.lda, newdata = train)$posterior
predict_label_c1 = (result[,2]+result[,3])>result[,1]
y_value = test$outcome
y_value = train$outcome
er = Error.rate(Fit = predict_label_c1, Y=y_value)
accracy = 1-er
accracy
y_value = train$still.alive
er = Error.rate(Fit = predict_label_c1, Y=y_value)
accracy = 1-er
accracy
